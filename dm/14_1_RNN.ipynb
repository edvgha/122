{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "466ec641-040d-4c1f-8bbd-b0b5131ff22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_xh shape: torch.Size([2, 5])\n",
      "W_hh shape: torch.Size([2, 2])\n",
      "b_xh shape: torch.Size([2])\n",
      "b_hh shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "rnn_layer = nn.RNN(input_size=5, hidden_size=2, num_layers=1, batch_first=True) \n",
    "\n",
    "w_xh = rnn_layer.weight_ih_l0\n",
    "w_hh = rnn_layer.weight_hh_l0\n",
    "b_xh = rnn_layer.bias_ih_l0\n",
    "b_hh = rnn_layer.bias_hh_l0\n",
    "\n",
    "print('W_xh shape:', w_xh.shape)\n",
    "print('W_hh shape:', w_hh.shape)\n",
    "print('b_xh shape:', b_xh.shape)\n",
    "print('b_hh shape:', b_hh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "514a7c25-222a-4e8b-afce-daffaf93f49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq = torch.tensor([[1.0]*5, [2.0]*5, [3.0]*5]).float()\n",
    "x_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b377e576-dd94-452b-9ce0-dee52da6e19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 0 =>\n",
      "   Input           : [[1. 1. 1. 1. 1.]]\n",
      "   Hidden          : [[-0.4701929  0.5863904]]\n",
      "   Output (manual) : [[-0.3519801   0.52525216]]\n",
      "   RNN output      : [[-0.3519801   0.52525216]]\n",
      "\n",
      "Time step 1 =>\n",
      "   Input           : [[2. 2. 2. 2. 2.]]\n",
      "   Hidden          : [[-0.88883156  1.2364397 ]]\n",
      "   Output (manual) : [[-0.68424344  0.76074266]]\n",
      "   RNN output      : [[-0.68424344  0.76074266]]\n",
      "\n",
      "Time step 2 =>\n",
      "   Input           : [[3. 3. 3. 3. 3.]]\n",
      "   Hidden          : [[-1.3074701  1.886489 ]]\n",
      "   Output (manual) : [[-0.8649416   0.90466356]]\n",
      "   RNN output      : [[-0.8649416   0.90466356]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## output of the simple RNN:\n",
    "output, hn = rnn_layer(torch.reshape(x_seq, (1, 3, 5)))\n",
    "\n",
    "## manually computing the output:\n",
    "out_man = []\n",
    "for t in range(3):\n",
    "    xt = torch.reshape(x_seq[t], (1, 5))\n",
    "    print(f'Time step {t} =>')\n",
    "    print('   Input           :', xt.numpy())\n",
    "    \n",
    "    ht = torch.matmul(xt, torch.transpose(w_xh, 0, 1)) + b_xh    \n",
    "    print('   Hidden          :', ht.detach().numpy())\n",
    "    \n",
    "    if t>0:\n",
    "        prev_h = out_man[t-1]\n",
    "    else:\n",
    "        prev_h = torch.zeros((ht.shape))\n",
    "\n",
    "    ot = ht + torch.matmul(prev_h, torch.transpose(w_hh, 0, 1)) + b_hh\n",
    "    ot = torch.tanh(ot)\n",
    "    out_man.append(ot)\n",
    "    print('   Output (manual) :', ot.detach().numpy())\n",
    "    print('   RNN output      :', output[:, t].detach().numpy())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cb1972-df0e-45e9-a2b0-f04352f46d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
