{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8537a18f-6404-4cda-8d8b-0ac2e759b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "class FullBayes:\n",
    "    def __init__(self, filename):\n",
    "        self.df = pd.read_csv(filename, sep=',', header=None)\n",
    "        self.df.columns = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width','class']\n",
    "        \n",
    "        self.n_points = int(self.df.shape[0] * 0.7)\n",
    "        # Bootstrap\n",
    "        train_indices = np.random.randint(self.df.shape[0], size=self.n_points)\n",
    "        self.df_train = self.df.iloc[train_indices]\n",
    "        # Test points\n",
    "        test_indices = np.setdiff1d(np.arange(self.df.shape[0]), train_indices)\n",
    "        self.df_test = self.df.iloc[test_indices]\n",
    "        \n",
    "        gb = self.df_train.groupby('class')\n",
    "        self.group_names = list(gb.groups)\n",
    "        self.groups = [gb.get_group(x) for x in gb.groups]\n",
    "        self.n_points_per_group = [x.shape[0] for x in self.groups]\n",
    "        self.prior_per_group = [x / (self.n_points + 0.0) for x in self.n_points_per_group]\n",
    "        self.mean_per_group = [x.mean(numeric_only=True) for x in self.groups]\n",
    "        self.centered_groups = [x - self.mean_per_group[i] for i, x in enumerate(self.groups)]\n",
    "        self.cov_per_group = [x.cov() for x in self.groups]\n",
    "    \n",
    "    def fit(self):\n",
    "        return self.prior_per_group, self.mean_per_group, self.cov_per_group\n",
    "    \n",
    "    def predict(self):\n",
    "        X = self.df_test[['sepal-length', 'sepal-width', 'petal-length', 'petal-width']]\n",
    "        y_true = self.df_test[['class']].squeeze()\n",
    "\n",
    "        res = np.empty((X.shape[0], len(self.cov_per_group)))\n",
    "        for i, el in enumerate(self.cov_per_group):\n",
    "            cov = self.cov_per_group[i].to_numpy()\n",
    "            mean = self.mean_per_group[i].to_numpy()\n",
    "            normal = multivariate_normal.pdf(X, mean=mean, cov=cov) * self.prior_per_group[i]\n",
    "            res[:, i] = normal\n",
    "        pred = np.argmax(res, axis=1)\n",
    "        y_pred = pd.DataFrame(pred).apply(lambda x: self.group_names[x[0]], axis=1, raw=True)\n",
    "        n_errors = np.count_nonzero(np.not_equal(y_pred.to_numpy(), y_true.to_numpy()))\n",
    "        return y_pred, y_true, n_errors / (0.0 + y_true.shape[0])\n",
    "        \n",
    "    \n",
    "    def score(self):\n",
    "        _, _, error_rate = self.predict()\n",
    "        return error_rate\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c10bbe7f-46cf-4c67-a50a-fc96e9b855b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fBayes = FullBayes('iris.data')\n",
    "fBayes.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6166778-5a12-47b1-a06d-c518ed99b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self, filename):\n",
    "        self.df = pd.read_csv(filename, sep=',', header=None)\n",
    "        self.df.columns = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width','class']\n",
    "        \n",
    "        self.n_points = int(self.df.shape[0] * 0.7)\n",
    "        # Bootstrap\n",
    "        train_indices = np.random.randint(self.df.shape[0], size=self.n_points)\n",
    "        self.df_train = self.df.iloc[train_indices]\n",
    "        # Test points\n",
    "        test_indices = np.setdiff1d(np.arange(self.df.shape[0]), train_indices)\n",
    "        self.df_test = self.df.iloc[test_indices]\n",
    "        \n",
    "        gb = self.df.groupby('class')\n",
    "        self.group_names = list(gb.groups)\n",
    "        self.groups = [gb.get_group(x) for x in gb.groups]\n",
    "        self.n_points_per_group = [x.shape[0] for x in self.groups]\n",
    "        self.prior_per_group = [x / (self.n_points + 0.0) for x in self.n_points_per_group]\n",
    "        self.mean_per_group = [x.mean(numeric_only=True) for x in self.groups]\n",
    "        self.centered_groups = [x - self.mean_per_group[i] for i, x in enumerate(self.groups)]\n",
    "        self.cov_per_group = [x.cov() for x in self.groups]\n",
    "    \n",
    "    def fit(self):\n",
    "        return self.prior_per_group, self.mean_per_group, self.cov_per_group\n",
    "    \n",
    "    def predict(self):\n",
    "        X = self.df_test[['sepal-length', 'sepal-width', 'petal-length', 'petal-width']].to_numpy()\n",
    "        n_attributes = X.shape[1]\n",
    "        y_true = self.df_test[['class']].squeeze()\n",
    "\n",
    "        res = np.empty((X.shape[0], len(self.cov_per_group)))\n",
    "        for i, el in enumerate(self.cov_per_group):\n",
    "            cov = self.cov_per_group[i].to_numpy()\n",
    "            mean = self.mean_per_group[i].to_numpy()\n",
    "            prior = self.prior_per_group[i]\n",
    "            normal = np.ones(X.shape[0])\n",
    "            for j in range(n_attributes):\n",
    "                normal = normal * multivariate_normal.pdf(X[:, j], mean=mean[j], cov=cov[j, j])\n",
    "            res[:, i] = normal * prior\n",
    "        pred = np.argmax(res, axis=1)\n",
    "        y_pred = pd.DataFrame(pred).apply(lambda x: self.group_names[x[0]], axis=1, raw=True)\n",
    "        n_errors = np.count_nonzero(np.not_equal(y_pred.to_numpy(), y_true.to_numpy()))\n",
    "        return y_pred, y_true, n_errors / (0.0 + y_true.shape[0])\n",
    "        \n",
    "    \n",
    "    def score(self):\n",
    "        _, _, error_rate = self.predict()\n",
    "        return error_rate\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa8e4228-1560-4856-aec1-78b9d5197f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02564102564102564"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fBayes = NaiveBayes('iris.data')\n",
    "fBayes.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d50fca-5012-4648-b01d-c45f029983e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-score:  -0.085610608506712\n",
      "95% conf:  Accept H0: both classifires has similar performance\n",
      "z-score:  2.0657124051604376\n",
      "99% conf:  Accept H0: both classifires has similar performance\n",
      "z-score:  4.451950976612078\n",
      "95% conf:  Reject H0: classifires have significantly different performance\n",
      "z-score:  2.2381042041280463\n",
      "99% conf:  Accept H0: both classifires has similar performance\n",
      "z-score:  1.6579297369548605\n",
      "95% conf:  Accept H0: both classifires has similar performance\n",
      "z-score:  0.5274646052085252\n",
      "99% conf:  Accept H0: both classifires has similar performance\n",
      "z-score:  0.7317809085107079\n",
      "95% conf:  Accept H0: both classifires has similar performance\n",
      "z-score:  0.6728210322911085\n",
      "99% conf:  Accept H0: both classifires has similar performance\n",
      "z-score:  2.6809767306850008\n",
      "95% conf:  Reject H0: classifires have significantly different performance\n",
      "z-score:  1.7256488921623931\n",
      "99% conf:  Accept H0: both classifires has similar performance\n",
      "z-score:  2.6469332155844114\n",
      "95% conf:  Reject H0: classifires have significantly different performance\n",
      "z-score:  2.291841652758369\n",
      "99% conf:  Accept H0: both classifires has similar performance\n",
      "z-score:  1.979125697873089\n",
      "95% conf:  Accept H0: both classifires has similar performance\n",
      "z-score:  1.4173971707577993\n",
      "99% conf:  Accept H0: both classifires has similar performance\n",
      "z-score:  3.065919505856923\n",
      "95% conf:  Reject H0: classifires have significantly different performance\n",
      "z-score:  1.4037021020463438\n",
      "99% conf:  Accept H0: both classifires has similar performance\n",
      "z-score:  1.7301036989104508\n",
      "95% conf:  Accept H0: both classifires has similar performance\n",
      "z-score:  1.3726413999376328\n",
      "99% conf:  Accept H0: both classifires has similar performance\n",
      "z-score:  4.011225952503951\n",
      "95% conf:  Reject H0: classifires have significantly different performance\n",
      "z-score:  2.2946815416707627\n",
      "99% conf:  Accept H0: both classifires has similar performance\n"
     ]
    }
   ],
   "source": [
    "def Paired_T_Test(t_alpha_half, K):\n",
    "    delta = np.empty(K)\n",
    "    for i in range(K):\n",
    "        score_NB = NaiveBayes('iris.data').score()\n",
    "        score_FB = FullBayes('iris.data').score()\n",
    "        delta[i] = score_NB - score_FB\n",
    "    mean = delta.mean()\n",
    "    std = delta.std()\n",
    "    Z = (np.sqrt(K) * mean) / std\n",
    "    print('z-score: ', Z)\n",
    "    if Z >= -t_alpha_half and Z <= t_alpha_half:\n",
    "        return 'Accept H0: both classifires has similar performance'\n",
    "    \n",
    "    return 'Reject H0: classifires have significantly different performance'\n",
    "\n",
    "#https://www.stat.colostate.edu/inmem/gumina/st201/pdf/Utts-Heckard_t-Table.pdf\n",
    "\n",
    "for i in range(10):\n",
    "    #95%\n",
    "    r = Paired_T_Test(2.05, 30)\n",
    "    print('95% conf: ', r)\n",
    "    #99%\n",
    "    r = Paired_T_Test(2.76, 30)\n",
    "    print('99% conf: ', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cef362-c267-40de-b4f4-341ab9ebf498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
