{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907c843a-7b0a-4449-b531-4bb9770c9c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length: 1112350\n",
      "Unique Characters: 80\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Reading and processing text\n",
    "with open('1268-0.txt', 'r', encoding=\"utf8\") as fp:\n",
    "    text=fp.read()\n",
    "    \n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "print('Total Length:', len(text))\n",
    "print('Unique Characters:', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6c984dc-1c2e-49e1-a441-bb640f100923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape:  (1112350,)\n",
      "THE MYSTERIOUS       == Encoding ==>  [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28]  == Reverse  ==>  ISLAND\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "\n",
    "text_encoded = np.array(\n",
    "    [char2int[ch] for ch in text],\n",
    "    dtype=np.int32)\n",
    "\n",
    "print('Text encoded shape: ', text_encoded.shape)\n",
    "\n",
    "print(text[:15], '     == Encoding ==> ', text_encoded[:15])\n",
    "print(text_encoded[15:21], ' == Reverse  ==> ', ''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "226b2e5a-0c59-4cb1-a731-ef0734664e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 -> T\n",
      "32 -> H\n",
      "29 -> E\n",
      "1 ->  \n",
      "37 -> M\n"
     ]
    }
   ],
   "source": [
    "for ex in text_encoded[:5]:\n",
    "    print('{} -> {}'.format(ex, char_array[ex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ac87ee-f869-4503-b2ee-333085c6a6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44 32 29  1 37 48 43 44 29 42 33 39 45 43  1 33 43 36 25 38 28  1  6  6\n",
      "  6  0  0  0  0  0 40 67 64 53 70 52 54 53  1 51]  ->  74\n",
      "'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'  ->  'y'\n"
     ]
    }
   ],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "\n",
    "text_chunks = [text_encoded[i:i+chunk_size] \n",
    "               for i in range(len(text_encoded)-chunk_size+1)] \n",
    "\n",
    "## inspection:\n",
    "for seq in text_chunks[:1]:\n",
    "    input_seq = seq[:seq_length]\n",
    "    target = seq[seq_length] \n",
    "    print(input_seq, ' -> ', target)\n",
    "    print(repr(''.join(char_array[input_seq])), \n",
    "          ' -> ', repr(''.join(char_array[target])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb23147b-4e6c-4898-a33e-62c538197f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edvard/.local/share/virtualenvs/pyml-ZGva7g9H/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/6s/fk_m3xbj6k99p2ch5cby1chr0000gn/T/ipykernel_42978/2527503007.py:15: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/distiller/project/pytorch/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  seq_dataset = TextDataset(torch.tensor(text_chunks))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text_chunk = self.text_chunks[idx]\n",
    "        return text_chunk[:-1].long(), text_chunk[1:].long()\n",
    "    \n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4520bf5c-5611-4f10-b6e7-6200efba1d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input (x): 'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'\n",
      "Target (y): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "\n",
      " Input (x): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "Target (y): 'E MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by '\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "    print(' Input (x):', repr(''.join(char_array[seq])))\n",
    "    print('Target (y):', repr(''.join(char_array[target])))\n",
    "    print()\n",
    "    if i == 1:\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a16eccc7-7025-41b9-ae93-6db917bc9cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee85451-5919-4014-8458-f1477d3d9980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    " \n",
    "batch_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "seq_dl = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07795618-b607-45e7-aa3c-01486fc74e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(80, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=80, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim) \n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, \n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        return hidden.to(device), cell.to(device)\n",
    "    \n",
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size) \n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6126fc0d-827f-443f-ac25-801299353644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 4.3722\n",
      "Epoch 500 loss: 1.3914\n",
      "Epoch 1000 loss: 1.3533\n",
      "Epoch 1500 loss: 1.2357\n",
      "Epoch 2000 loss: 1.2332\n",
      "Epoch 2500 loss: 1.2139\n",
      "Epoch 3000 loss: 1.1662\n",
      "Epoch 3500 loss: 1.1483\n",
      "Epoch 4000 loss: 1.1945\n",
      "Epoch 4500 loss: 1.1549\n",
      "Epoch 5000 loss: 1.0935\n",
      "Epoch 5500 loss: 1.1284\n",
      "Epoch 6000 loss: 1.1518\n",
      "Epoch 6500 loss: 1.1256\n",
      "Epoch 7000 loss: 1.1101\n",
      "Epoch 7500 loss: 1.1790\n",
      "Epoch 8000 loss: 1.1190\n",
      "Epoch 8500 loss: 1.1739\n",
      "Epoch 9000 loss: 1.1082\n",
      "Epoch 9500 loss: 1.1173\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "num_epochs = 10000 \n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    seq_batch, target_batch = next(iter(seq_dl))\n",
    "    seq_batch = seq_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        pred, hidden, cell = model(seq_batch[:, c], hidden, cell) \n",
    "        loss += loss_fn(pred, target_batch[:, c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()/seq_length\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch {epoch} loss: {loss:.4f}')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b863d1-3ea9-478e-b988-839d5cb67360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
